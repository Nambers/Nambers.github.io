<!DOCTYPE html>
<html lang="en" color-mode="light">

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="author" content="Eritque arcus" />
  <!-- Open Graph Description 简短摘要-->
  
  <!-- 用于搜索引擎的文章摘要 -->
  
  <meta name="description" content="Eritque arcus&#39;s blog" />
  
  
  
  <title>
    
      Python使用urllib/urllib3/requests库+beautifulsoup爬取网页 
      
      
      |
    
     Eritque arcus&#39;s blog
  </title>

  
    <link rel="apple-touch-icon" href="/images/avatar.png">
    <link rel="icon" href="/images/avatar.png">
  

  <!-- Raleway-Font -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Raleway:ital,wght@0,100..900;1,100..900&display=swap" rel="stylesheet">

  <!-- hexo site css -->
  <link rel="stylesheet" href="/css/main.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" />
  <!-- 代码块风格 -->
  

  <!-- jquery3.3.1 -->
  
    <script defer type="text/javascript" src="/plugins/jquery.min.js"></script>
  

  <!-- fancybox -->
  
    <link href="/plugins/jquery.fancybox.min.css" rel="stylesheet">
    <script defer type="text/javascript" src="/plugins/jquery.fancybox.min.js"></script>
  
  
<script src="/js/fancybox.js"></script>


  

  

  <script>
    var html = document.documentElement
    const colorMode = localStorage.getItem('color-mode')
    if (colorMode) {
      document.documentElement.setAttribute('color-mode', colorMode)
    }
  </script>
<meta name="generator" content="Hexo 7.1.1"></head>


  <body>
    <div id="app">
      <div class="header">
  <div class="avatar">
    <a href="/">
      <!-- 头像取消懒加载，添加no-lazy -->
      
        <img src="/images/avatar.png" alt="">
      
    </a>
    <div class="nickname"><a href="/">Eritque arcus</a></div>
  </div>
  <div class="navbar">
    <ul>
      
        <li class="nav-item" data-path="/">
          <a href="/">Home</a>
        </li>
      
        <li class="nav-item" data-path="/archives/">
          <a href="/archives/">Archives</a>
        </li>
      
        <li class="nav-item" data-path="/tags/">
          <a href="/tags/">Tags</a>
        </li>
      
        <li class="nav-item" data-path="/link/">
          <a href="/link/">Friends</a>
        </li>
      
        <li class="nav-item" data-path="/about/">
          <a href="/about/">About</a>
        </li>
      
        <li class="nav-item" data-path="/ctf-cheatsheet/">
          <a href="/ctf-cheatsheet/">CTF-cheatsheet</a>
        </li>
      
        <li class="nav-item" data-path="/files/">
          <a href="/files/">Files</a>
        </li>
      
        <li class="nav-item" data-path="https://www.travellings.cn/go.html">
          <a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.travellings.cn/go.html">Travelling</a>
        </li>
      
    </ul>
  </div>
</div>


<script src="/js/activeNav.js"></script>



      <div class="flex-container">
        <!-- 文章详情页，展示文章具体内容，url形式：https://yoursite/文章标题/ -->
<!-- 同时为「标签tag」，「朋友friend」，「分类categories」，「关于about」页面的承载页面，具体展示取决于page.type -->




  <!-- clipboard -->

  
    <script async type="text/javascript" src="/plugins/clipboard.min.js"></script>
  
  
<script src="/js/codeCopy.js"></script>







  

  

  

  
  <!-- 文章内容页 url形式：https://yoursite/文章标题/ -->
  <div class="container post-details" id="post-details">
    <div class="post-content">
      <div class="post-title">Python使用urllib/urllib3/requests库+beautifulsoup爬取网页</div>
      <div class="post-attach">
        <span class="post-pubtime">
          <i class="iconfont icon-updatetime mr-10" title="Update time"></i>
          2024-02-10 07:10:53
        </span>
        
              <span class="post-tags">
                <i class="iconfont icon-tags mr-10" title="Tags"></i>
                
                <span class="span--tag mr-8">
                  <a href="/tags/Python/" title="Python">
                    #Python
                  </a>
                </span>
                
                <span class="span--tag mr-8">
                  <a href="/tags/Web-crawler/" title="Web crawler">
                    #Web crawler
                  </a>
                </span>
                
              </span>
          
      </div>
      <div class="markdown-body">
        <blockquote>
<p>测试环境是python 3.8.1</p>
</blockquote>
<h2 id="urllib"><a href="#urllib" class="headerlink" title="urllib"></a>urllib</h2><p>urllib提供了一系列用于操作URL的功能。<br>urllib的request模块可以非常方便地抓取URL内容，也就是发送一个GET请求到指定的页面，然后返回HTTP的响应。</p>
<p>使用pip下载:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install urllib</span><br></pre></td></tr></table></figure>

<p>例如对百度搜索界面的抓取(<a target="_blank" rel="noopener external nofollow noreferrer" href="http://www.baidu.com/">www.baidu.com</a>)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">   headers = &#123;</span><br><span class="line">            <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;Keep-Alive&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;Accept&#x27;</span>: <span class="string">&#x27;text/html, application/xhtml+xml, */*&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;Accept-Language&#x27;</span>: <span class="string">&#x27;en-US,en;q=0.8,zh-Hans-CN;q=0.5,zh-Hans;q=0.3&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;Accept-Encoding&#x27;</span>: <span class="string">&#x27;gzip, deflate&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/6.1 (Windows NT 6.3; WOW64; Trident/7.0; rv:11.0) like Gecko&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;Host&#x27;</span>: <span class="string">&#x27;www.so.com&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;Referer&#x27;</span>: <span class="string">&#x27;https://www.so.com&#x27;</span></span><br><span class="line">        &#125;</span><br><span class="line">    respond = urllib.request.urlopen(<span class="string">&#x27;http://www.baidu.com&#x27;</span>, headers=headers)</span><br><span class="line">    <span class="built_in">print</span>(respond.read().decode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>参考网站:<br><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.liaoxuefeng.com/wiki/1016959663602400/1019223241745024">廖雪峰的官方网站</a></p>
<h2 id="urllib3"><a href="#urllib3" class="headerlink" title="urllib3"></a>urllib3</h2><p>urllib3是一个功能强大且友好的Python HTTP客户端。大多数Python生态系统已经使用urllib3，您也应该使用。urllib3带来了Python标准库中缺少的许多关键功能：</p>
<p>线程安全。<br>连接池。<br>客户端SSL &#x2F; TLS验证。<br>使用分段编码上传文件。<br>重试请求和处理HTTP重定向的助手。<br>支持gzip，deflate和brotli编码。<br>HTTP和SOCKS的代理支持。<br>100％的测试覆盖率。<br>urllib3功能强大且易于使用：<br>下载：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install urllib3</span><br></pre></td></tr></table></figure>
<p>例如抓取百度搜索界面(<a target="_blank" rel="noopener external nofollow noreferrer" href="http://www.baidu.com/">www.baidu.com</a>)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> urllib3</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    http = urllib3.PoolManager()</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;Keep-Alive&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Accept&#x27;</span>: <span class="string">&#x27;text/html, application/xhtml+xml, */*&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Accept-Language&#x27;</span>: <span class="string">&#x27;en-US,en;q=0.8,zh-Hans-CN;q=0.5,zh-Hans;q=0.3&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Accept-Encoding&#x27;</span>: <span class="string">&#x27;gzip, deflate&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/6.1 (Windows NT 6.3; WOW64; Trident/7.0; rv:11.0) like Gecko&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    r=http.request(<span class="string">&#x27;GET&#x27;</span>, <span class="string">&#x27;http://www.baidu.com&#x27;</span>, headers=headers)</span><br><span class="line">    <span class="built_in">print</span>(r.data)</span><br></pre></td></tr></table></figure>

<h2 id="requests"><a href="#requests" class="headerlink" title="requests"></a>requests</h2><p>我们已经讲解了Python内置的urllib模块和其升级版urllib3，用于访问网络资源。但是，它用起来比较麻烦，而且，缺少很多实用的高级功能。</p>
<p>更好的方案是使用requests。它是一个Python第三方库，处理URL资源特别方便。<br>下载：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install requests</span><br></pre></td></tr></table></figure>
<p>注意有 <strong>s</strong> 在&#x3D;&#x3D;requests&#x3D;&#x3D;中</p>
<p>例如抓取360搜索结果:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    keyword = <span class="string">&quot;123sad&quot;</span></span><br><span class="line">    keyword = <span class="built_in">input</span>(<span class="string">&quot;请输入你想搜索的内容&quot;</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">      <span class="comment">#添加headers防止被最简单的反爬虫阻止，在chrome按F12后点击Network中一个下滑查看</span></span><br><span class="line">        headers = &#123;</span><br><span class="line">            <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;Keep-Alive&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;Accept&#x27;</span>: <span class="string">&#x27;text/html, application/xhtml+xml, */*&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;Accept-Language&#x27;</span>: <span class="string">&#x27;en-US,en;q=0.8,zh-Hans-CN;q=0.5,zh-Hans;q=0.3&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;Accept-Encoding&#x27;</span>: <span class="string">&#x27;gzip, deflate&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/6.1 (Windows NT 6.3; WOW64; Trident/7.0; rv:11.0) like Gecko&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;Host&#x27;</span>: <span class="string">&#x27;www.so.com&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;Referer&#x27;</span>: <span class="string">&#x27;https://www.so.com&#x27;</span></span><br><span class="line">        &#125;</span><br><span class="line">        page = <span class="number">1</span></span><br><span class="line">        <span class="comment">#GET参数列表</span></span><br><span class="line">        kv = &#123;<span class="string">&#x27;q&#x27;</span>: keyword, <span class="string">&#x27;ie&#x27;</span>: <span class="string">&#x27;utf-8&#x27;</span>, <span class="string">&#x27;pn&#x27;</span>: page&#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># requests.ReadTimeout(60)</span></span><br><span class="line">        r = requests.get(<span class="string">&quot;http://www.so.com/s&quot;</span>, headers=headers,</span><br><span class="line">                         params=kv)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;url:&#x27;</span>+r.request.url)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        html = r.text</span><br><span class="line">        <span class="built_in">print</span>(html)</span><br><span class="line">    <span class="keyword">except</span> requests.HTTPError <span class="keyword">as</span> a:</span><br><span class="line">        <span class="built_in">print</span>(a)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;爬取失败&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;失败&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>参考网站：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.liaoxuefeng.com/wiki/1016959663602400/1183249464292448">廖雪峰的官方网站</a></p>
<h2 id="笔者在爬取时遇到的问题"><a href="#笔者在爬取时遇到的问题" class="headerlink" title="笔者在爬取时遇到的问题"></a>笔者在爬取时遇到的问题</h2><h3 id="1-结果不全"><a href="#1-结果不全" class="headerlink" title="1.结果不全"></a>1.结果不全</h3><p>笔者在vs code 中执行时，结果显示不全<br>如果结果显示不全，需要在cmd中执行文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python xxx.py</span><br></pre></td></tr></table></figure>
<h3 id="2-‘抓取失败’"><a href="#2-‘抓取失败’" class="headerlink" title="2.‘抓取失败’"></a>2.‘抓取失败’</h3><p>显示该问题，一般是因为IP被屏蔽<br>目前很多搜索引擎都装备了反爬虫，这个时候需要重启路由器（重新拨号）或者挂代理(proxy)，或者试一试别的搜索引擎，笔者抓取百度时频繁出现错误，只能抓取360搜索</p>
<h3 id="3-返回乱码"><a href="#3-返回乱码" class="headerlink" title="3.返回乱码"></a>3.返回乱码</h3><p>对返回结果解码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">html.decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="进阶"><a href="#进阶" class="headerlink" title="进阶"></a>进阶</h2><h3 id="urllib-1"><a href="#urllib-1" class="headerlink" title="urllib"></a>urllib</h3><h4 id="parse"><a href="#parse" class="headerlink" title="parse"></a>parse</h4><p>使用parse模块拼接参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">params = &#123;<span class="string">&#x27;ie&#x27;</span>: <span class="string">&#x27;utf-8&#x27;</span>, <span class="string">&#x27;wd&#x27;</span>: <span class="string">&#x27;python是这个世界上最好的语言&#x27;</span>&#125;</span><br><span class="line">url = <span class="string">&#x27;www.baidu.com/s?&#x27;</span>+urllib.parse.urlencode(params)</span><br><span class="line"><span class="built_in">print</span>(url)</span><br></pre></td></tr></table></figure>
<p>结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">www.baidu.com/s?ie=utf-8&amp;wd=python%E6%98%AF%E8%BF%99%E4%B8%AA%E4%B8%96%E7%95%8C%E4%B8%8A%E6%9C%80%E5%A5%BD%E7%9A%84%E8%AF%AD%E8%A8%80</span><br></pre></td></tr></table></figure>
<h4 id="error"><a href="#error" class="headerlink" title="error"></a>error</h4><p>在urllib中设置了两个主要异常类，一个是URLError，一个是HTTPError</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">...</span><br><span class="line"><span class="keyword">except</span> urllib.error.HTTPError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(e.code)<span class="comment">#错误码</span></span><br><span class="line">    <span class="built_in">print</span>(e.reason)<span class="comment">#错误的原因</span></span><br><span class="line">    pring(e.headers)<span class="comment">#响应的报头</span></span><br><span class="line"><span class="keyword">except</span> urllib.error.URLError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(e)</span><br></pre></td></tr></table></figure>
<h3 id="re库"><a href="#re库" class="headerlink" title="re库"></a>re库</h3><p>re库是用来分析网页返回结果的正则库<br>安装:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install re</span><br></pre></td></tr></table></figure>
<p>正则:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">pattern = re.<span class="built_in">compile</span>(</span><br><span class="line">            <span class="string">r&#x27;&lt;li class=&quot;res-list&quot; data-lazyload=&quot;1&quot;&gt;&lt;h3 class=&quot;res-title &quot;&gt;&lt;a href=&quot;(.*?)&quot;&#x27;</span>, re.S)</span><br><span class="line">        results = pattern.findall(html)</span><br></pre></td></tr></table></figure>
<p>其中,<em>re.compile</em>是创建正则式,<em>findall</em>是在文本中匹配全部，并返回数组格式的数据<br>有关正则表达式写法和更多数据请看<a target="_blank" rel="noopener external nofollow noreferrer" href="https://docs.python.org/zh-cn/3/library/re.html">官方文档</a></p>
<blockquote>
<p>笔者推荐使用requests库</p>
</blockquote>
<h2 id="beautifulsoup"><a href="#beautifulsoup" class="headerlink" title="beautifulsoup"></a>beautifulsoup</h2><p>Beautiful Soup 是一个可以从HTML或XML文件中提取数据的Python库.它能够通过你喜欢的转换器实现惯用的文档导航,查找,修改文档的方式.Beautiful Soup会帮你节省数小时甚至数天的工作时间.<br>pip安装:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install bs4</span><br></pre></td></tr></table></figure>
<p>如果要使用<code>lxml解析器</code>请参考<a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.cnblogs.com/lvdongjie/p/11286599.html">博客园</a>，因为下载太慢，笔者使<code>用html解析器</code></p>
<p>使用beautifulsoup提取指定的html元素:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">soup = BeautifulSoup(req.text, <span class="string">&quot;html&quot;</span>)</span><br><span class="line"><span class="comment">#req是resquests返回的结果</span></span><br><span class="line">soup.find(name=<span class="string">&quot;div&quot;</span>, attrs=&#123;<span class="string">&quot;class&quot;</span> :<span class="string">&quot;a&quot;</span>,<span class="string">&quot;id&quot;</span>:<span class="string">&quot;b&quot;</span>&#125;)</span><br><span class="line"><span class="comment">#提取&lt;div class=&quot;a&quot; id=&quot;b&quot;&gt;的元素内容</span></span><br><span class="line">soup.select(<span class="string">&quot;.a&quot;</span>)</span><br><span class="line"><span class="comment">#提取class=&quot;a&quot;的元素,可以使用# .等选择器</span></span><br><span class="line">human_list=beautifulsoup(<span class="string">&quot;&lt;p class=&#x27;a&#x27;&gt;&lt;/p&gt;&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(human_list.p[<span class="string">&quot;class&quot;</span>])<span class="comment">#输出 a</span></span><br></pre></td></tr></table></figure>
<p>如果要取html元素里的内容，用<code>xx.string</code>或者.text<br><a target="_blank" rel="noopener external nofollow noreferrer" href="http://www.jsphp.net/python/show-24-214-1.html">参考链接</a><br><a target="_blank" rel="noopener external nofollow noreferrer" href="https://beautifulsoup.readthedocs.io/zh_CN/v4.4.0/">点我跳转官方文档</a></p>
<h2 id="例子"><a href="#例子" class="headerlink" title="例子:"></a>例子:</h2><p>以下代码爬取了<code>https://www.baidu.com/s?ie=UTF-8&amp;wd=afs</code>的第一条搜索结果的名字</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;https://www.baidu.com/s?ie=UTF-8&amp;wd=afs&quot;</span></span><br><span class="line">headers = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.87 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">req = requests.get(url, headers=headers)</span><br><span class="line"><span class="comment">#soup = BeautifulSoup(req.text, &quot;lxml&quot;)#使用lxml解析器</span></span><br><span class="line">soup = BeautifulSoup(req.text, <span class="string">&quot;html&quot;</span>)<span class="comment">#使用html解析器</span></span><br><span class="line">human_list=soup.find(name=<span class="string">&quot;div&quot;</span>, attrs=&#123;<span class="string">&quot;class&quot;</span> :<span class="string">&quot;c-abstract&quot;</span>&#125;)</span><br><span class="line">human_list=<span class="built_in">str</span>(human_list)</span><br><span class="line">human_list=human_list.replace(<span class="string">&#x27;&lt;div class=&quot;c-abstract c-abstract-en&quot;&gt;&#x27;</span>,<span class="string">&quot;&quot;</span>)</span><br><span class="line">human_list=human_list.replace(<span class="string">&quot;&lt;/div&gt;&quot;</span>,<span class="string">&quot;&quot;</span>)</span><br><span class="line">human_list=human_list.replace(<span class="string">&quot;\n&quot;</span>,<span class="string">&quot;&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(human_list)</span><br></pre></td></tr></table></figure>
<p>输出:</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">em</span>&gt;</span>AFS<span class="tag">&lt;/<span class="name">em</span>&gt;</span> study abroad, education and volunteer programs empower people of all ages and backgrounds with essential intercultural knowledge, skills and understanding.</span><br></pre></td></tr></table></figure>

<center><b>END</b></center>
      </div>
      
        <div class="prev-or-next">
          <div class="post-foot-next">
            
          </div>
          <div class="post-attach">
            <span class="post-pubtime">
              <i class="iconfont icon-updatetime mr-10" title="Update time"></i>
              2024-02-10 07:10:53
            </span>
            
                  <span class="post-tags">
                    <i class="iconfont icon-tags mr-10" title="Tags"></i>
                    
                    <span class="span--tag mr-8">
                      <a href="/tags/Python/" title="Python">
                        #Python
                      </a>
                    </span>
                    
                    <span class="span--tag mr-8">
                      <a href="/tags/Web-crawler/" title="Web crawler">
                        #Web crawler
                      </a>
                    </span>
                    
                  </span>
              
          </div>
          <div class="post-foot-prev">
            
              <a href="/2020/01/27/%E4%BD%BF%E7%94%A8html+css+js%E5%88%B6%E4%BD%9C%E7%BD%91%E7%AB%99%E6%95%99%E7%A8%8B/" target="_self">
                <span>Next</span>
                <i class="iconfont icon-chevronright"></i>
              </a>
            
          </div>
        </div>
      
    </div>
    
  <div id="btn-catalog" class="btn-catalog">
    <i class="iconfont icon-catalog"></i>
  </div>
  <div class="post-catalog hidden" id="catalog">
    <div class="title">Contents</div>
    <div class="catalog-content">
      
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#urllib"><span class="toc-text">urllib</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#urllib3"><span class="toc-text">urllib3</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#requests"><span class="toc-text">requests</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%94%E8%80%85%E5%9C%A8%E7%88%AC%E5%8F%96%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-text">笔者在爬取时遇到的问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E7%BB%93%E6%9E%9C%E4%B8%8D%E5%85%A8"><span class="toc-text">1.结果不全</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E2%80%98%E6%8A%93%E5%8F%96%E5%A4%B1%E8%B4%A5%E2%80%99"><span class="toc-text">2.‘抓取失败’</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E8%BF%94%E5%9B%9E%E4%B9%B1%E7%A0%81"><span class="toc-text">3.返回乱码</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%9B%E9%98%B6"><span class="toc-text">进阶</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#urllib-1"><span class="toc-text">urllib</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#parse"><span class="toc-text">parse</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#error"><span class="toc-text">error</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#re%E5%BA%93"><span class="toc-text">re库</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#beautifulsoup"><span class="toc-text">beautifulsoup</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BE%8B%E5%AD%90"><span class="toc-text">例子:</span></a></li></ol>
      
    </div>
  </div>

  
<script src="/js/catalog.js"></script>




    
  </div>


        
<div class="footer">
  <div class="social">
    <ul>
      
        <li>
          
              <a title="github" target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/Nambers">
                <i class="fa-brands fa-github fa-lg"></i>
              </a>
              
        </li>
        
        <li>
          
            <a title="email" href="mailto:eritque-arcus@ikuyo.dev">
              <i class="fa-solid fa-envelope fa-lg"></i>
            </a>
            
        </li>
        
    </ul>
  </div>
  
    
    
      <div class="footer-more">
          
            <a href="https://github.com/Nambers" rel="external nofollow noreferrer" target="_blank">Copyright ©2020-2024 Eritque Arcus</a>
           
      </div>
    
  
    
    
      <div class="footer-more">
          
            <a href="https://github.com/zchengsite/hexo-theme-oranges" rel="external nofollow noreferrer" target="_blank">Theme by Oranges | Powered by Hexo</a>
           
      </div>
    
  
    
    
      <div class="footer-more">
          
            <a href="https://icp.gov.moe/?keyword=20222242" target="_blank">萌ICP备20222242号</a>
           
      </div>
    
  
    
    
      <script async src="https://4-um4m1.ikuyo.dev/script.js" data-website-id="03f1081f-d820-47e8-84c9-245f9093244c"></script>
    
  
  
</div>

      </div>

      <div class="tools-bar">
        <div class="back-to-top tools-bar-item hidden">
  <a href="javascript: void(0)" rel="external nofollow noreferrer">
    <i class="iconfont icon-chevronup"></i>
  </a>
</div>


<script src="/js/backtotop.js"></script>



        


        
  <div class="tools-bar-item theme-icon" id="switch-color-scheme">
    <a href="javascript: void(0)" rel="external nofollow noreferrer">
      <i id="theme-icon" class="iconfont icon-moon"></i>
    </a>
  </div>

  
<script src="/js/colorscheme.js"></script>





        

      </div>
    </div>
  </body>
</html>
